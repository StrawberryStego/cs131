import time
import os
from pyspark.sql import SparkSession
import matplotlib.pyplot as plt

spark = SparkSession.builder.appName("ws78").getOrCreate()

file_sizes = []
runtimes = []

for n in range(1, 6):
    csv_file = f"data_{n}.csv"
    size_in_mb = os.path.getsize(csv_file) / (1024 * 1024)
    file_sizes.append(size_in_mb)
    
    start = time.time()
    
    df = spark.read.option("header", False).option("inferSchema", True).csv(csv_file)
    df.groupBy("_c0").avg("_c1").show()

    end = time.time()
    runtimes.append(end - start)
spark.stop()

plt.plot(file_sizes, runtimes, marker='o')
plt.xlabel("File Size (MB)")
plt.ylabel("Run Time (seconds)")
plt.title("Run Time vs. File Size")
plt.show()
